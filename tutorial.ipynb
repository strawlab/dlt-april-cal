{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dlt-april-cal\n",
    "\n",
    "This directory contains materials to implement a camera calibration as follows:\n",
    "\n",
    "- April Tag fiducial markers placed at known locations in the environment which\n",
    "  will define the calibrated coordinate system.\n",
    "\n",
    "**Note of caution** This experiment was performed using materials I had\n",
    "available at home and done in a \"quick and dirty\" approach. For \"real usage\",\n",
    "one would ideally use better quality materials, such as sheets which are glued\n",
    "to rigid and flat surface. This documentation may be updated with higher quality\n",
    "images in the future.\n",
    "\n",
    "## Overview of Experimental Setup\n",
    "\n",
    "We have a number of april tags at known locations in the environment. These are\n",
    "printed on two sheets of A4 paper, sheet \"Z0\" and sheet \"Z1\". We arrange these\n",
    "so that, ideally, the paper sheets are perfectly planar and are parallel to the\n",
    "z=0 plane. In fact, we define sheet \"Z0\" to be at the plane z=0 and \"Z1\" to be\n",
    "at a fixed distance away (here 15 cm).\n",
    "\n",
    "![overview.jpg](overview.jpg)\n",
    "\n",
    "## Extracting Pixel Coordinates of the April Tags\n",
    "\n",
    "We will generate a CSV file for each view of the april tag locations. In the\n",
    "first view (\"z0\"), we record the positions of the April Tags in the \"Z0\" A4\n",
    "sheet. In the second view (\"z1\"), we record the positions in the \"Z1\" A4 sheet.\n",
    "\n",
    "### Option 1: use Strand Camera\n",
    "\n",
    "If [Strand Camera](https://strawlab.org/strand-cam) with April Tag detection\n",
    "enabled, (including as part of [Braid](https://strawlab.org/braid)), the\n",
    "position of April Tags may be detected automatically and saved to CSV files\n",
    "using the tools in the \"April Tag Detection\" panel.\n",
    "\n",
    "### Option 2: use `gst-plugin-apriltag`\n",
    "\n",
    "After building `gst-plugin-apriltag` [according to its\n",
    "instructions](https://github.com/strawlab/strand-braid/blob/main/gst-plugin-apriltag/README.md),\n",
    "here are the commands I used at the command line:\n",
    "\n",
    "```bash\n",
    "gst-launch-1.0 filesrc location=z0-0.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z0-0.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z0-1.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z0-1.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z0-2.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z0-2.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z1-0.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z1-0.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z1-1.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z1-1.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z1-2.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z1-2.jpg.csv\n",
    "\n",
    "cat z0-0.jpg.csv > z0.csv\n",
    "tail -n +2 z0-1.jpg.csv >> z0.csv\n",
    "tail -n +2 z0-2.jpg.csv >> z0.csv\n",
    "\n",
    "cat z1-0.jpg.csv > z1.csv\n",
    "tail -n +2 z1-1.jpg.csv >> z1.csv\n",
    "tail -n +2 z1-2.jpg.csv >> z1.csv\n",
    "```\n",
    "\n",
    "This generates files `z0.csv` and `z1.csv` which are here in the `data/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the calibration\n",
    "\n",
    "Below we will use Python in this notebook to actually create geometric models of our cameras (i.e. to perform the calibration.)\n",
    "\n",
    "First, we define the known 3D coordinates of our fiducial makers (April Tags). These are constructed by design to have a known, fixed location. Therefore, we \"hard code\" these known locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1_METERS = 0.15\n",
    "\n",
    "def id2xyz(idnum):\n",
    "    \n",
    "    # These values are the X and Y positions of the A4 sheets as defined in the Inkscape\n",
    "    # `drawing.svg` file and rendered in the `Z0.pdf` and `Z1.pdf` file. All units are meters.\n",
    "    \n",
    "    x0a = -0.0935\n",
    "    x1a = 0.08777\n",
    "    \n",
    "    x0b = -0.0838\n",
    "    x1b = 0.0833\n",
    "    \n",
    "    y0 = -0.0938\n",
    "    y1 = 0.0872\n",
    "    \n",
    "    za = 0.0\n",
    "    zb = Z1_METERS\n",
    "\n",
    "    rownum = idnum // 45\n",
    "    colnum = idnum % 45\n",
    "    \n",
    "    if colnum >= 15:\n",
    "        # sheet z1\n",
    "        colnum -= 15\n",
    "        x0 = x0b\n",
    "        x1 = x1b        \n",
    "        z = zb\n",
    "    else:\n",
    "        # sheet z0\n",
    "        x0 = x0a\n",
    "        x1 = x1a\n",
    "        z = za\n",
    "    \n",
    "    xrange = x1-x0\n",
    "    xnum = 13\n",
    "    dx = xrange/xnum\n",
    "\n",
    "    yrange = y1-y0\n",
    "    ynum = 14\n",
    "    dy = yrange/ynum\n",
    "    \n",
    "    x = colnum * dx + x0\n",
    "    y = rownum * dy + y0\n",
    "    return (x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the Python libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pymvg.calibration # install with `pip install pymvg`\n",
    "import pymvg.multi_camera_system\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know the pixel dimensions of the camera, so here we take one of the images we saved with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_height, cam_width, _ = imageio.imread('data/z0-0.jpg').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here read the pixel coordinates of each fiducial marker as seen by the camera and extracted by the April Tags software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low = pd.read_csv('data/z0.csv')\n",
    "df_high = pd.read_csv('data/z1.csv')\n",
    "\n",
    "df = pd.concat((df_low,df_low,df_high))\n",
    "\n",
    "# Create \"human\" names for x and y center.\n",
    "df['x_px'] = df['h02']\n",
    "df['y_px'] = df['h12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple frames of data for the same 3D locations of the April Tags, and these may vary a little due to pixel noise, etc. So we average the pixel coordinate for all tags together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average all data for the same tag.\n",
    "df = df.groupby(['id'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute the known 3D location of each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x'],df['y'],df['z'] = zip(*df['id'].map(id2xyz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the calibration for this camera. We use the DLT algorithm to find the best linear camera model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World coords in 3D\n",
    "X = np.array((df['x'].values, df['y'].values, df['z'].values)).T\n",
    "# Pixel coords in 2D\n",
    "x = np.array((df['x_px'].values, df['y_px'].values)).T\n",
    "# Run the calibration\n",
    "dlt_results = pymvg.calibration.DLT(X, x, width=cam_width, height=cam_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam {\"name\": \"cam\",\n",
      "     \"width\": 1080,\n",
      "     \"height\": 720,\n",
      "     \"P\": [[ 1236.529440113545, 33.472107763674444, 612.1598733360305, 0 ],\n",
      "           [ 0, 1195.4219088509992, 376.07459949749807, 0 ],\n",
      "           [ 0, 0, 1.0, 0 ]],\n",
      "     \"K\": [[ 1236.529440113545, 33.472107763674444, 612.1598733360305 ],\n",
      "           [ 0, 1195.4219088509992, 376.07459949749807 ],\n",
      "           [ 0, 0, 1.0 ]],\n",
      "     \"D\": [ 0, 0, 0, 0, 0 ],\n",
      "     \"R\": [[ 1.0, 0, 0 ],\n",
      "           [ 0, 1.0, 0 ],\n",
      "           [ 0, 0, 1.0 ]],\n",
      "     \"Q\": [[ 0.9970827706033963, -0.023609764140094636, 0.07258462373742876 ],\n",
      "           [ 0.0024396801100375603, 0.9603300480207533, 0.2788552435035395 ],\n",
      "           [ -0.0762889017276805, -0.27786467552696714, 0.9575861452462006 ]],\n",
      "     \"translation\": [ 0.0024788095729054924, -0.039395393537037846, 0.44329464984721323 ]\n",
      "    }\n",
      "mean_reproj_error 3.24576562286359\n"
     ]
    }
   ],
   "source": [
    "for key in dlt_results:\n",
    "    print(key, dlt_results[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's name our specific camera for which these results apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1 = dlt_results['cam']\n",
    "cam1.name = 'cam1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above steps for each camera in the camera system from the point \"We here read the pixel coordinates of each fiducial marker\". Create a new variable (like `cam2`, `cam3` and so on) for each camera in your camera system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = [cam1]\n",
    "cam_system = pymvg.multi_camera_system.MultiCameraSystem(cameras)\n",
    "cam_system.save_to_pymvg_file(\"calibration_pymvg.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "\n",
    "- Show how to convert pymvg YAML file to Braid/Flydra XML calibration file.\n",
    "- Use gradient descent to set distortion parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
