{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# dlt-april-cal\n",
    "\n",
    "This directory contains materials to implement a camera calibration as follows:\n",
    "\n",
    "- April Tag fiducial markers placed at known locations in the environment which\n",
    "  will define the calibrated coordinate system.\n",
    "\n",
    "**Note of caution** This experiment was performed using materials I had\n",
    "available at home and done in a \"quick and dirty\" approach. For \"real usage\",\n",
    "one would ideally use better quality materials, such as sheets which are glued\n",
    "to rigid and flat surface. This documentation may be updated with higher quality\n",
    "images in the future.\n",
    "\n",
    "## Overview of Experimental Setup\n",
    "\n",
    "We have a number of april tags at known locations in the environment. These are\n",
    "printed on two sheets of A4 paper, sheet \"Z0\" and sheet \"Z1\". We arrange these\n",
    "so that, ideally, the paper sheets are perfectly planar and are parallel to the\n",
    "z=0 plane. In fact, we define sheet \"Z0\" to be at the plane z=0 and \"Z1\" to be\n",
    "at a fixed distance away (here 15 cm).\n",
    "\n",
    "![overview.jpg](overview.jpg)\n",
    "\n",
    "## Extracting Pixel Coordinates of the April Tags\n",
    "\n",
    "We will generate a CSV file for each view of the april tag locations. In the\n",
    "first view (\"z0\"), we record the positions of the April Tags in the \"Z0\" A4\n",
    "sheet. In the second view (\"z1\"), we record the positions in the \"Z1\" A4 sheet.\n",
    "\n",
    "### Option 1: use Strand Camera\n",
    "\n",
    "If [Strand Camera](https://strawlab.org/strand-cam) with April Tag detection\n",
    "enabled, (including as part of [Braid](https://strawlab.org/braid)), the\n",
    "position of April Tags may be detected automatically and saved to CSV files\n",
    "using the tools in the \"April Tag Detection\" panel.\n",
    "\n",
    "### Option 2: use `gst-plugin-apriltag`\n",
    "\n",
    "After building `gst-plugin-apriltag` [according to its\n",
    "instructions](https://github.com/strawlab/strand-braid/blob/main/gst-plugin-apriltag/README.md),\n",
    "here are the commands I used at the command line:\n",
    "\n",
    "```bash\n",
    "gst-launch-1.0 filesrc location=z0-0.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z0-0.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z0-1.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z0-1.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z0-2.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z0-2.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z1-0.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z1-0.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z1-1.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z1-1.jpg.csv\n",
    "gst-launch-1.0 filesrc location=z1-2.jpg ! decodebin ! videoconvert ! apriltagdetector family=standard-41h12 ! filesink location=z1-2.jpg.csv\n",
    "\n",
    "cat z0-0.jpg.csv > z0.csv\n",
    "tail -n +2 z0-1.jpg.csv >> z0.csv\n",
    "tail -n +2 z0-2.jpg.csv >> z0.csv\n",
    "\n",
    "cat z1-0.jpg.csv > z1.csv\n",
    "tail -n +2 z1-1.jpg.csv >> z1.csv\n",
    "tail -n +2 z1-2.jpg.csv >> z1.csv\n",
    "```\n",
    "\n",
    "This generates files `z0.csv` and `z1.csv` which are here in the `data/` directory."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running the calibration\n",
    "\n",
    "Below we will use Python in this notebook to actually create geometric models of our cameras (i.e. to perform the calibration.)\n",
    "\n",
    "First, we define the known 3D coordinates of our fiducial makers (April Tags). These are constructed by design to have a known, fixed location. Therefore, we \"hard code\" these known locations:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "Z1_METERS = 0.15\n",
    "\n",
    "def id2xyz(idnum):\n",
    "    \n",
    "    # These values are the X and Y positions of the A4 sheets as defined in the Inkscape\n",
    "    # `drawing.svg` file and rendered in the `Z0.pdf` and `Z1.pdf` file. All units are meters.\n",
    "    \n",
    "    x0a = -0.0935\n",
    "    x1a = 0.08777\n",
    "    \n",
    "    x0b = -0.0838\n",
    "    x1b = 0.0833\n",
    "    \n",
    "    y0 = -0.0938\n",
    "    y1 = 0.0872\n",
    "    \n",
    "    za = 0.0\n",
    "    zb = Z1_METERS\n",
    "\n",
    "    rownum = idnum // 45\n",
    "    colnum = idnum % 45\n",
    "    \n",
    "    if colnum >= 15:\n",
    "        # sheet z1\n",
    "        colnum -= 15\n",
    "        x0 = x0b\n",
    "        x1 = x1b        \n",
    "        z = zb\n",
    "    else:\n",
    "        # sheet z0\n",
    "        x0 = x0a\n",
    "        x1 = x1a\n",
    "        z = za\n",
    "    \n",
    "    xrange = x1-x0\n",
    "    xnum = 13\n",
    "    dx = xrange/xnum\n",
    "\n",
    "    yrange = y1-y0\n",
    "    ynum = 14\n",
    "    dy = yrange/ynum\n",
    "    \n",
    "    x = colnum * dx + x0\n",
    "    y = rownum * dy + y0\n",
    "    return (x, y, z)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define the `DistortionOptimizer` class which we will call later to perform an\n",
    "optimization for distortion based on reprojection error. The radial and\n",
    "tangential distortions in the \"plumb bob\" model will be changed and the best\n",
    "fitting values (those that minimize the mean reprojection error) will be found."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class DistortionOptimizer:\n",
    "    def __init__(self, X3d, x2d, linear_cam):\n",
    "        self.X3d = X3d\n",
    "        self.x2d = x2d\n",
    "        self.linear_cam = linear_cam\n",
    "    def mean_reproj_err(self, d):\n",
    "        \"\"\"Find the mean reprojection error for d, the distortion parameters\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        d - a length 4 sequence [radial1, radial2, tangential1, tangential2]\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Although pymvg uses a length-5 distortion vector (radial1, radial2,\n",
    "        tangential1, tangential2, radial3) to fit the ROS/OpenCV plumb_bob\n",
    "        distortion model, the Flydra XML calibration format does not use the\n",
    "        radial3 distortion term. Therefore, we optimize the distortion while\n",
    "        keeping radial3 fixed to zero.\n",
    "        \"\"\"\n",
    "        d = np.array([d[0], d[1], d[2], d[3], 0.0], dtype=float)\n",
    "        cam = self.linear_cam\n",
    "        cam.distortion = d\n",
    "        x2d_reproj = cam.project_3d_to_pixel(self.X3d)\n",
    "\n",
    "        # calculate point-by-point reprojection error\n",
    "        err = np.sqrt(np.sum( (self.x2d - x2d_reproj)**2, axis=1 ))\n",
    "\n",
    "        # find mean reprojection error across all pixels\n",
    "        mean_reproj_err = np.mean(err)\n",
    "        return mean_reproj_err"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we import the Python libraries we need."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pymvg.calibration # install with `pip install pymvg`\n",
    "import pymvg.multi_camera_system\n",
    "import imageio\n",
    "import scipy.optimize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to know the pixel dimensions of the camera, so here we take one of the images we saved with it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "cam_height, cam_width, _ = imageio.imread('data/z0-0.jpg').shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We here read the pixel coordinates of each fiducial marker as seen by the camera and extracted by the April Tags software."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_low = pd.read_csv('data/z0.csv')\n",
    "df_high = pd.read_csv('data/z1.csv')\n",
    "\n",
    "df = pd.concat((df_low,df_low,df_high))\n",
    "\n",
    "# Create \"human\" names for x and y center.\n",
    "df['x_px'] = df['h02']\n",
    "df['y_px'] = df['h12']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have multiple frames of data for the same 3D locations of the April Tags, and these may vary a little due to pixel noise, etc. So we average the pixel coordinate for all tags together."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Average all data for the same tag.\n",
    "df = df.groupby(['id'], as_index=False).mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we compute the known 3D location of each tag."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df['x'],df['y'],df['z'] = zip(*df['id'].map(id2xyz))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can run the calibration for this camera. We use the DLT algorithm to find the best linear camera model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# World coords in 3D\n",
    "X3d = np.array((df['x'].values, df['y'].values, df['z'].values)).T\n",
    "# Pixel coords in 2D\n",
    "x2d = np.array((df['x_px'].values, df['y_px'].values)).T\n",
    "# Run the calibration\n",
    "dlt_results = pymvg.calibration.DLT(X3d, x2d, width=cam_width, height=cam_height)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's print our results from this DLT-based calibration. In this first step, we have not fit the distortion parameters yet."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for key in dlt_results:\n",
    "    print(key, dlt_results[key])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cam {\"name\": \"cam\",\n",
      "     \"width\": 1080,\n",
      "     \"height\": 720,\n",
      "     \"P\": [[ 1236.529440113545, 33.472107763674444, 612.1598733360305, 0 ],\n",
      "           [ 0, 1195.4219088509992, 376.07459949749807, 0 ],\n",
      "           [ 0, 0, 1.0, 0 ]],\n",
      "     \"K\": [[ 1236.529440113545, 33.472107763674444, 612.1598733360305 ],\n",
      "           [ 0, 1195.4219088509992, 376.07459949749807 ],\n",
      "           [ 0, 0, 1.0 ]],\n",
      "     \"D\": [ 0, 0, 0, 0, 0 ],\n",
      "     \"R\": [[ 1.0, 0, 0 ],\n",
      "           [ 0, 1.0, 0 ],\n",
      "           [ 0, 0, 1.0 ]],\n",
      "     \"Q\": [[ 0.9970827706033963, -0.023609764140094636, 0.07258462373742876 ],\n",
      "           [ 0.0024396801100375603, 0.9603300480207533, 0.2788552435035395 ],\n",
      "           [ -0.0762889017276805, -0.27786467552696714, 0.9575861452462006 ]],\n",
      "     \"translation\": [ 0.0024788095729054924, -0.039395393537037846, 0.44329464984721323 ]\n",
      "    }\n",
      "mean_reproj_error 3.24576562286359\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's name our specific camera for which these results apply."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "cam1 = dlt_results['cam']\n",
    "cam1.name = 'cam1'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can (optionally) perform an optimization of the distortion terms while\n",
    "keeping the other terms fixed. This step is entirely optional and can be left\n",
    "out. Also may also be possible that allowing the optimizer to adjust other\n",
    "parameters of the camera model, such as the optical center and focal length,\n",
    "would improve performance further."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "optimizer = DistortionOptimizer(X3d, x2d, cam1)\n",
    "\n",
    "optimizer_results = scipy.optimize.minimize(optimizer.mean_reproj_err, np.zeros(4))\n",
    "print(optimizer_results)\n",
    "\n",
    "d = optimizer_results.x\n",
    "\n",
    "# Now update the distortion model with our new parameters.\n",
    "cam1.distortion = np.array([d[0], d[1], d[2], d[3], 0.0], dtype=float)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      fun: 3.179452297913353\n",
      " hess_inv: array([[ 5.28823908e-01, -5.97150508e+00,  7.56185605e-03,\n",
      "         3.05037658e-03],\n",
      "       [-5.97150508e+00,  9.45360594e+01,  7.23558780e-02,\n",
      "        -4.59097289e-02],\n",
      "       [ 7.56185605e-03,  7.23558780e-02,  1.50075208e-03,\n",
      "        -6.96244414e-05],\n",
      "       [ 3.05037658e-03, -4.59097289e-02, -6.96244414e-05,\n",
      "         7.95712279e-04]])\n",
      "      jac: array([ 1.78813934e-07, -1.78813934e-07,  2.98023224e-06,  3.87430191e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 110\n",
      "      nit: 17\n",
      "     njev: 22\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-0.15287156,  0.86896914, -0.01219555,  0.00143297])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Repeat the above steps for each camera in the camera system from the point \"We here read the pixel coordinates of each fiducial marker\". Create a new variable (like `cam2`, `cam3` and so on) for each camera in your camera system."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "cameras = [cam1]\n",
    "cam_system = pymvg.multi_camera_system.MultiCameraSystem(cameras)\n",
    "cam_system.save_to_pymvg_file(\"calibration_pymvg.json\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: \n",
    "\n",
    "- Show how to convert pymvg JSON file to Braid/Flydra XML calibration file."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('dlt-april-cal': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "41c4487e4b3af60010beec9079c2c021c2ea8dcaf24cac7ffe1c33ed8021a370"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}